{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the library\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import math\n",
    "from geopy.distance import vincenty\n",
    "import urllib2, requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cPickle as pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "from tsp_solver.greedy import solve_tsp\n",
    "\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = '../../../../Browser/Documents/mapapikey.txt'\n",
    "api = pd.read_csv(fn)\n",
    "api = api.columns[0]\n",
    "gmaps = googlemaps.Client(key=api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msor/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: gzip transfer encoding is experimental!\n"
     ]
    }
   ],
   "source": [
    "import mechanize\n",
    "import cookielib\n",
    "\n",
    "# Browser\n",
    "br = mechanize.Browser()\n",
    "\n",
    "# Cookie Jar\n",
    "cj = cookielib.LWPCookieJar()\n",
    "br.set_cookiejar(cj)\n",
    "\n",
    "# Browser options\n",
    "br.set_handle_equiv(True)\n",
    "br.set_handle_gzip(True)\n",
    "br.set_handle_redirect(True)\n",
    "br.set_handle_referer(True)\n",
    "br.set_handle_robots(False)\n",
    "\n",
    "# Follows refresh 0 but not hangs on refresh > 0\n",
    "br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)\n",
    "\n",
    "# Want debugging messages?\n",
    "#br.set_debug_http(True)\n",
    "#br.set_debug_redirects(True)\n",
    "#br.set_debug_responses(True)\n",
    "\n",
    "# User-Agent setup\n",
    "# br.addheaders = [('User-agent': 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 5.1; rv:14.0) Gecko/20100101 Firefox/14.0.1',\n",
    "          'Referer': 'http://www.google.com'}\n",
    "br.addheaders = [header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle save data\n",
    "def save_data(db, filename):\n",
    "    with open('assets/datasets/{}.p'.format(filename), 'wb') as fp:\n",
    "        pickle.dump(db, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # pickle load data\n",
    "def load_data(filename):\n",
    "    with open('assets/datasets/{}.p'.format(filename), 'rb') as fp:\n",
    "        read_content = pickle.load(fp)\n",
    "        return read_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges = load_data('edges') # dict indexed by lat long\n",
    "locations = load_data('attraction_locations')\n",
    "location_details = load_data('location_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attractions = pd.read_excel('assets/datasets/ShortAttractions.xlsx')\n",
    "# attractions.columns = ['index', 'Locations']\n",
    "attractions_list = list(attractions['Locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get lat long from google maps api\n",
    "def get_coordinates(attractions, add_hk=True):\n",
    "    attractions = attractions.encode('utf-8')\n",
    "    if add_hk:\n",
    "        query = attractions + ', Hong Kong'\n",
    "    else:\n",
    "        query = attractions\n",
    "    geocode_result = gmaps.geocode(query)\n",
    "    if geocode_result == []:\n",
    "        return None,None,None,None\n",
    "    else:\n",
    "        latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "        longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "        return attractions, latitude, longitude, geocode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# attractions mapping to map the attractions to the geo location details\n",
    "def location_mapping(attractions):\n",
    "    locations = {}\n",
    "    location_details = {}\n",
    "    for i in tqdm(attractions):\n",
    "        if i not in locations.keys():\n",
    "            loc, lat, lon, loc_details = get_coordinates(i.decode(encoding='UTF-8'))\n",
    "            if loc != None:\n",
    "                locations[loc] = (lat, lon)\n",
    "                location_details[loc] = loc_details\n",
    "    return locations, location_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert location dictionary to location dataframe\n",
    "def loc_dict2df(locations):\n",
    "    df = []\n",
    "    for i, j in locations.items():\n",
    "        df.append([i, j[0],j[1]])\n",
    "    df = pd.DataFrame(df, columns=['Location', 'Latitude', 'Longitude'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "locations, location_details = location_mapping(attractions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clear_places = []\n",
    "for i in location_details:\n",
    "    clear_places.append([i, location_details[i][0]['formatted_address']])\n",
    "clear_places = pd.DataFrame(clear_places, columns=['Location','Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attractions_list = list(clear_places[clear_places.Address != \"Hong Kong\"]['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# locations, location_details = location_mapping(attractions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code will export the locations and lat long coordinates for plotting on tableau\n",
    "\n",
    "location_coord = loc_dict2df(locations)\n",
    "location_coord.to_csv('assets/datasets/location_lat_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_data(locations, 'attraction_locations')\n",
    "# save_data(location_details, 'location_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pair up 'nodes' (locations) to create 'edges' (routes) of the graphs\n",
    "def node_pairing(locations):\n",
    "    location_pair = []\n",
    "    for i in range(len(locations)):\n",
    "        for j in range(i+1,len(locations)):\n",
    "            location_pair.append( [ {locations.keys()[i] : locations[locations.keys()[i]]}, {locations.keys()[j] : locations[locations.keys()[j]]} ] )\n",
    "            location_pair.append( [ {locations.keys()[j] : locations[locations.keys()[j]]}, {locations.keys()[i] : locations[locations.keys()[i]]} ] )\n",
    "    return location_pair\n",
    "location_pair = node_pairing(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the suggested route from the government webpage given lat lon...\n",
    "def get_route(start_lat, start_lon, end_lat, end_lon):\n",
    "    latlong = 'http://m.hketransport.gov.hk/getRouteSearchResult.php?ctl26=&ctl30=&ctl36=&ctl40=&ctl41=&ctl42=&slat={}&slon={}&elat={}&elon={}&DDL_BUF_O=400&DDL_BUF_D=400&RB_MODE=RB_MODE1&Btn_RS=Route%20Search&lang=0'.format(start_lat, start_lon, end_lat, end_lon)\n",
    "    r = br.open(latlong)\n",
    "    html = r.read()\n",
    "    return BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def route_finder_hk(location_pair_index):\n",
    "    i = location_pair_index\n",
    "    start_lat = i[0][i[0].keys()[0]][0]\n",
    "    start_lon = i[0][i[0].keys()[0]][1]\n",
    "    end_lat = i[1][i[1].keys()[0]][0]\n",
    "    end_lon = i[1][i[1].keys()[0]][1]\n",
    "    return start_lat, start_lon, end_lat, end_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert direction result into list from page \n",
    "def parse_table(table):\n",
    "    \"\"\" Get data from table \"\"\"\n",
    "    tmp = [\n",
    "        [cell.get_text().strip() for cell in row.find_all(['th', 'td'])]\n",
    "           for row in table.find_all('tr')\n",
    "    ]\n",
    "    result = []\n",
    "    for i in tmp:\n",
    "        if i != [] and i != ['Route Search'] and i != ['Route Info'] and i != ['Other Info'] and i != ['']:\n",
    "            if len(i) <= 2:\n",
    "                result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert direction list into dict from list\n",
    "def build_dict(tbl_list):\n",
    "    loc_dict = {}\n",
    "    cross = []\n",
    "    for i in range(len(tbl_list)):\n",
    "        if tbl_list[i] != [] :\n",
    "            if 'Choice ' in tbl_list[i][0][:7]:\n",
    "                cross.append(i)\n",
    "    cross.append(len(tbl_list))\n",
    "    \n",
    "    for i in range(len(cross)-1):\n",
    "        loc_dict[tbl_list[cross[i]][0]] = tbl_list[cross[i]:cross[i+1]]\n",
    "    return loc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert direction dict into pd\n",
    "def build_table(loc_dict):\n",
    "    loc_table = []\n",
    "    for i, j in loc_dict.items():\n",
    "        choice = int(i[7:])\n",
    "        cost = j[-1:][0][0]\n",
    "        time = j[-1:][0][1]\n",
    "        loc_table.append( [choice, cost, time] )\n",
    "    loc_table = pd.DataFrame(loc_table, columns=['choice', 'cost', 'time'])\n",
    "    loc_table.sort_values('choice',inplace=True)\n",
    "    loc_table.index = range(len(loc_table))\n",
    "    return loc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# route details\n",
    "def route_builder(location_pair, saver = 50, renew=False):\n",
    "    if renew:\n",
    "        edges = {}\n",
    "    else:\n",
    "        edges = load_data('edges')\n",
    "    counter = 0\n",
    "    for i in tqdm(range(len(location_pair))):\n",
    "        tmp = {}\n",
    "        a = location_pair[i][0][location_pair[i][0].keys()[0]]\n",
    "        b = location_pair[i][1][location_pair[i][1].keys()[0]]\n",
    "        keys = [a,b]\n",
    "        if str(keys) not in edges.keys():\n",
    "            start_lat, start_lon, end_lat, end_lon = route_finder_hk(location_pair[i])\n",
    "            table = get_route(start_lat, start_lon, end_lat, end_lon)\n",
    "            tbl_list = parse_table(table) # get list of table items from html\n",
    "            loc_dict = build_dict(tbl_list) # convert the list of choices into logical dictionary\n",
    "            df = build_table(loc_dict) # build the choices summary into a dataframe\n",
    "            tmp['detail'] = loc_dict # build detail to the dict\n",
    "            tmp['result'] = df # build summary to the dict\n",
    "            tmp['from'] = location_pair[i][0].keys()[0]\n",
    "            tmp['to'] = location_pair[i][1].keys()[0]\n",
    "            edges[str(keys)] = tmp\n",
    "            \n",
    "            counter = counter + 1\n",
    "            if counter == saver :\n",
    "                save_data(edges, 'edges')\n",
    "                counter = 0\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_distance_approx(start_lat, start_lon, end_lat, end_lon):\n",
    "    dist = vincenty((start_lat,start_lon), (end_lat, end_lon)).km\n",
    "    return dist # in kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the location pair actually has a lot of duplications, as places with different share the same lat-lon coordinates\n",
    "keys_location_pair = []\n",
    "edge_keys = {}\n",
    "for i in location_pair:\n",
    "    s_coord = i[0].items()[0][1]\n",
    "    e_coord = i[1].items()[0][1]\n",
    "    key = str([s_coord, e_coord])\n",
    "    keys_location_pair.append(key)\n",
    "    edge_keys[key] = i\n",
    "\n",
    "# make unique location pair\n",
    "unique_location_pair = []\n",
    "for i,j in edge_keys.items():\n",
    "    unique_location_pair.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [19:04<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "edges = route_builder(unique_location_pair, renew=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(edges, 'edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
